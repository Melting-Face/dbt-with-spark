# Project Structure

This document describes the directory structure of this project.

## `/standalone_delta`

This directory contains a Docker-based setup for a standalone Delta Lake environment. It includes Dockerfiles and a `docker-compose.yml` file to spin up services like Spark and MinIO to work with Delta Lake.

*   `hive/`: Contains the Dockerfile and related source code for the Hive Metastore service.
*   `minio/`: Contains the Dockerfile and related source code for the MinIO service, which provides S3-compatible object storage.
*   `spark/`: Contains the Dockerfile and related source code for the Spark service, which is used for data processing.
*   `.env`: Defines environment variables used by the services in the `docker-compose.yml` file.
*   `docker-compose.yml`: The main Docker Compose file that defines and orchestrates the services (Spark, Hive, MinIO) for the Delta Lake environment.

## `/standalone_iceberg`

This directory contains a Docker-based setup for a standalone Apache Iceberg environment. It includes Dockerfiles and a `docker-compose.yml` file to spin up services like Spark, Hive Metastore, and MinIO to work with Apache Iceberg.

*   `data/`: This directory is used by MinIO to store warehouse data.
*   `hive/`: Contains the Dockerfile and related source code for the Hive Metastore service.
*   `logs/`: Contains log files for dbt runs within this environment.
*   `minio/`: Contains the Dockerfile and related source code for the MinIO service.
*   `mysql/`: Contains data files for the MySQL database, which is used as the backend for the Hive Metastore.
*   `spark/`: Contains the Dockerfile and related source code for the Spark service.
*   `spark_events/`: Stores Spark event logs for monitoring and debugging Spark applications.
*   `spark_logs/`: Contains log files generated by the Spark services (Master, Worker, History Server).
*   `.env`: Defines environment variables for the services in the `docker-compose.yml` file.
*   `docker-compose.yml`: The main Docker Compose file that defines and orchestrates the services (Spark, Hive, MinIO, MySQL) for the Iceberg environment.
