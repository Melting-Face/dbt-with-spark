{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1b418c10-2a8b-4a78-9638-759f6cdcb432",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sparknlp\n",
    "from sparknlp.pretrained import PretrainedPipeline\n",
    "from pyspark.sql import SparkSession"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2e92ebe8-cf80-4176-b8e1-7b38e13e16f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "Setting Spark log level to \"INFO\".\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "07:52:21.008 [Thread-3] INFO  org.apache.spark.resource.ResourceUtils - ==============================================================\n",
      "07:52:21.011 [Thread-3] INFO  org.apache.spark.resource.ResourceUtils - No custom resources configured for spark.driver.\n",
      "07:52:21.011 [Thread-3] INFO  org.apache.spark.resource.ResourceUtils - ==============================================================\n",
      "07:52:21.011 [Thread-3] INFO  org.apache.spark.SparkContext - Submitted application: Spark NLP\n",
      "07:52:21.039 [Thread-3] INFO  org.apache.spark.resource.ResourceProfile - Default ResourceProfile created, executor resources: Map(cores -> name: cores, amount: 1, script: , vendor: , memory -> name: memory, amount: 1024, script: , vendor: , offHeap -> name: offHeap, amount: 0, script: , vendor: ), task resources: Map(cpus -> name: cpus, amount: 1.0)\n",
      "07:52:21.048 [Thread-3] INFO  org.apache.spark.resource.ResourceProfile - Limiting resource is cpus at 1 tasks per executor\n",
      "07:52:21.049 [Thread-3] INFO  org.apache.spark.resource.ResourceProfileManager - Added ResourceProfile id: 0\n",
      "07:52:21.102 [Thread-3] INFO  org.apache.spark.SecurityManager - Changing view acls to: root\n",
      "07:52:21.102 [Thread-3] INFO  org.apache.spark.SecurityManager - Changing modify acls to: root\n",
      "07:52:21.103 [Thread-3] INFO  org.apache.spark.SecurityManager - Changing view acls groups to: \n",
      "07:52:21.103 [Thread-3] INFO  org.apache.spark.SecurityManager - Changing modify acls groups to: \n",
      "07:52:21.103 [Thread-3] INFO  org.apache.spark.SecurityManager - SecurityManager: authentication disabled; ui acls disabled; users with view permissions: root; groups with view permissions: EMPTY; users with modify permissions: root; groups with modify permissions: EMPTY\n",
      "07:52:21.290 [Thread-3] WARN  org.apache.spark.util.Utils - Service 'sparkDriver' could not bind on port 7078. Attempting port 7079.\n",
      "07:52:21.293 [Thread-3] WARN  org.apache.spark.util.Utils - Service 'sparkDriver' could not bind on port 7079. Attempting port 7080.\n",
      "07:52:21.296 [Thread-3] WARN  org.apache.spark.util.Utils - Service 'sparkDriver' could not bind on port 7080. Attempting port 7081.\n",
      "07:52:21.302 [Thread-3] INFO  org.apache.spark.util.Utils - Successfully started service 'sparkDriver' on port 7081.\n",
      "07:52:21.324 [Thread-3] INFO  org.apache.spark.SparkEnv - Registering MapOutputTracker\n",
      "07:52:21.355 [Thread-3] INFO  org.apache.spark.SparkEnv - Registering BlockManagerMaster\n",
      "07:52:21.376 [Thread-3] INFO  org.apache.spark.storage.BlockManagerMasterEndpoint - Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information\n",
      "07:52:21.376 [Thread-3] INFO  org.apache.spark.storage.BlockManagerMasterEndpoint - BlockManagerMasterEndpoint up\n",
      "07:52:21.379 [Thread-3] INFO  org.apache.spark.SparkEnv - Registering BlockManagerMasterHeartbeat\n",
      "07:52:21.397 [Thread-3] INFO  org.apache.spark.storage.DiskBlockManager - Created local directory at /tmp/blockmgr-04f24931-c73c-47da-b553-4266e149d8b5\n",
      "07:52:21.411 [Thread-3] INFO  org.apache.spark.storage.memory.MemoryStore - MemoryStore started with capacity 434.4 MiB\n",
      "07:52:21.423 [Thread-3] INFO  org.apache.spark.SparkEnv - Registering OutputCommitCoordinator\n",
      "07:52:21.462 [Thread-3] INFO  org.sparkproject.jetty.util.log - Logging initialized @1891ms to org.sparkproject.jetty.util.log.Slf4jLog\n",
      "07:52:21.528 [Thread-3] INFO  org.apache.spark.ui.JettyUtils - Start Jetty 0.0.0.0:4040 for SparkUI\n",
      "07:52:21.539 [Thread-3] INFO  org.sparkproject.jetty.server.Server - jetty-9.4.54.v20240208; built: 2024-02-08T19:42:39.027Z; git: cef3fbd6d736a21e7d541a5db490381d95a2047d; jvm 11.0.25+9\n",
      "07:52:21.568 [Thread-3] INFO  org.sparkproject.jetty.server.Server - Started @1998ms\n",
      "07:52:21.593 [Thread-3] WARN  org.apache.spark.util.Utils - Service 'SparkUI' could not bind on port 4040. Attempting port 4041.\n",
      "07:52:21.599 [Thread-3] INFO  org.sparkproject.jetty.server.AbstractConnector - Started ServerConnector@36e6f4a7{HTTP/1.1, (http/1.1)}{0.0.0.0:4041}\n",
      "07:52:21.599 [Thread-3] INFO  org.apache.spark.util.Utils - Successfully started service 'SparkUI' on port 4041.\n",
      "07:52:21.614 [Thread-3] INFO  org.sparkproject.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@6818a05d{/,null,AVAILABLE,@Spark}\n",
      "07:52:21.669 [Thread-3] INFO  org.apache.spark.scheduler.FairSchedulableBuilder - Fair scheduler configuration not found, created default pool: default, schedulingMode: FAIR, minShare: 0, weight: 1\n",
      "07:52:21.711 [appclient-register-master-threadpool-0] INFO  org.apache.spark.deploy.client.StandaloneAppClient$ClientEndpoint - Connecting to master spark://spark-master:7077...\n",
      "07:52:21.764 [netty-rpc-connection-0] INFO  org.apache.spark.network.client.TransportClientFactory - Successfully created connection to spark-master/10.89.2.5:7077 after 29 ms (0 ms spent in bootstraps)\n",
      "07:52:21.845 [dispatcher-event-loop-4] INFO  org.apache.spark.scheduler.cluster.StandaloneSchedulerBackend - Connected to Spark cluster with app ID app-20250915075221-0002\n",
      "07:52:21.856 [Thread-3] WARN  org.apache.spark.util.Utils - Service 'org.apache.spark.network.netty.NettyBlockTransferService' could not bind on port 7079. Attempting port 7080.\n",
      "07:52:21.860 [Thread-3] WARN  org.apache.spark.util.Utils - Service 'org.apache.spark.network.netty.NettyBlockTransferService' could not bind on port 7080. Attempting port 7081.\n",
      "07:52:21.863 [Thread-3] WARN  org.apache.spark.util.Utils - Service 'org.apache.spark.network.netty.NettyBlockTransferService' could not bind on port 7081. Attempting port 7082.\n",
      "07:52:21.864 [Thread-3] INFO  org.apache.spark.util.Utils - Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 7082.\n",
      "07:52:21.864 [Thread-3] INFO  org.apache.spark.network.netty.NettyBlockTransferService - Server created on spark-master 0.0.0.0:7082\n",
      "07:52:21.866 [Thread-3] INFO  org.apache.spark.storage.BlockManager - Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy\n",
      "07:52:21.866 [Thread-3] INFO  org.apache.spark.storage.BlockManager - external shuffle service port = 7337\n",
      "07:52:21.874 [Thread-3] INFO  org.apache.spark.storage.BlockManagerMaster - Registering BlockManager BlockManagerId(driver, spark-master, 7082, None)\n",
      "07:52:21.877 [dispatcher-BlockManagerMaster] INFO  org.apache.spark.storage.BlockManagerMasterEndpoint - Registering block manager spark-master:7082 with 434.4 MiB RAM, BlockManagerId(driver, spark-master, 7082, None)\n",
      "07:52:21.878 [Thread-3] INFO  org.apache.spark.storage.BlockManagerMaster - Registered BlockManager BlockManagerId(driver, spark-master, 7082, None)\n",
      "07:52:21.879 [Thread-3] INFO  org.apache.spark.storage.BlockManager - Initialized BlockManager: BlockManagerId(driver, spark-master, 7082, None)\n",
      "07:52:22.123 [Thread-3] INFO  org.apache.spark.deploy.history.RollingEventLogFilesWriter - Logging events to file:/opt/spark/events/eventlog_v2_app-20250915075221-0002/events_1_app-20250915075221-0002.zstd\n",
      "07:52:22.205 [Thread-3] INFO  org.apache.spark.util.Utils - Using initial executors = 0, max of spark.dynamicAllocation.initialExecutors, spark.dynamicAllocation.minExecutors and spark.executor.instances\n",
      "07:52:22.228 [Thread-3] INFO  org.sparkproject.jetty.server.handler.ContextHandler - Stopped o.s.j.s.ServletContextHandler@6818a05d{/,null,STOPPED,@Spark}\n",
      "07:52:22.229 [Thread-3] INFO  org.sparkproject.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@616b2540{/jobs,null,AVAILABLE,@Spark}\n",
      "07:52:22.229 [Thread-3] INFO  org.sparkproject.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@39b82318{/jobs/json,null,AVAILABLE,@Spark}\n",
      "07:52:22.230 [Thread-3] INFO  org.sparkproject.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@3bfab7ff{/jobs/job,null,AVAILABLE,@Spark}\n",
      "07:52:22.230 [Thread-3] INFO  org.sparkproject.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@48dec87f{/jobs/job/json,null,AVAILABLE,@Spark}\n",
      "07:52:22.231 [Thread-3] INFO  org.sparkproject.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@72e0f5c1{/stages,null,AVAILABLE,@Spark}\n",
      "07:52:22.232 [Thread-3] INFO  org.sparkproject.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@169b187e{/stages/json,null,AVAILABLE,@Spark}\n",
      "07:52:22.232 [Thread-3] INFO  org.sparkproject.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@2b52e7f0{/stages/stage,null,AVAILABLE,@Spark}\n",
      "07:52:22.233 [Thread-3] INFO  org.sparkproject.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@5076bb7b{/stages/stage/json,null,AVAILABLE,@Spark}\n",
      "07:52:22.233 [Thread-3] INFO  org.sparkproject.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@64e1e4c5{/stages/pool,null,AVAILABLE,@Spark}\n",
      "07:52:22.233 [Thread-3] INFO  org.sparkproject.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@6ae7a375{/stages/pool/json,null,AVAILABLE,@Spark}\n",
      "07:52:22.236 [Thread-3] INFO  org.sparkproject.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@5e0eec95{/storage,null,AVAILABLE,@Spark}\n",
      "07:52:22.237 [Thread-3] INFO  org.sparkproject.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@7d9a7248{/storage/json,null,AVAILABLE,@Spark}\n",
      "07:52:22.237 [Thread-3] INFO  org.sparkproject.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@765052c1{/storage/rdd,null,AVAILABLE,@Spark}\n",
      "07:52:22.238 [Thread-3] INFO  org.sparkproject.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@7ee2ce89{/storage/rdd/json,null,AVAILABLE,@Spark}\n",
      "07:52:22.239 [Thread-3] INFO  org.sparkproject.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@4eb8010a{/environment,null,AVAILABLE,@Spark}\n",
      "07:52:22.239 [Thread-3] INFO  org.sparkproject.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@51820a30{/environment/json,null,AVAILABLE,@Spark}\n",
      "07:52:22.240 [Thread-3] INFO  org.sparkproject.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@318ea067{/executors,null,AVAILABLE,@Spark}\n",
      "07:52:22.240 [Thread-3] INFO  org.sparkproject.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@2951eb79{/executors/json,null,AVAILABLE,@Spark}\n",
      "07:52:22.241 [Thread-3] INFO  org.sparkproject.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@50a3f96d{/executors/threadDump,null,AVAILABLE,@Spark}\n",
      "07:52:22.242 [Thread-3] INFO  org.sparkproject.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@3478422{/executors/threadDump/json,null,AVAILABLE,@Spark}\n",
      "07:52:22.242 [Thread-3] INFO  org.sparkproject.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@f39793c{/executors/heapHistogram,null,AVAILABLE,@Spark}\n",
      "07:52:22.243 [Thread-3] INFO  org.sparkproject.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@48bd20c5{/executors/heapHistogram/json,null,AVAILABLE,@Spark}\n",
      "07:52:22.248 [Thread-3] INFO  org.sparkproject.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@3865972e{/static,null,AVAILABLE,@Spark}\n",
      "07:52:22.249 [Thread-3] INFO  org.sparkproject.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@33f17b13{/,null,AVAILABLE,@Spark}\n",
      "07:52:22.250 [Thread-3] INFO  org.sparkproject.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@5bfbb0f{/api,null,AVAILABLE,@Spark}\n",
      "07:52:22.251 [Thread-3] INFO  org.sparkproject.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@7a8a4808{/jobs/job/kill,null,AVAILABLE,@Spark}\n",
      "07:52:22.251 [Thread-3] INFO  org.sparkproject.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@38d29e65{/stages/stage/kill,null,AVAILABLE,@Spark}\n",
      "07:52:22.254 [Thread-3] INFO  org.sparkproject.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@54f0a27c{/metrics/json,null,AVAILABLE,@Spark}\n",
      "07:52:22.254 [Thread-3] INFO  org.apache.spark.scheduler.cluster.StandaloneSchedulerBackend - SchedulerBackend is ready for scheduling beginning after reached minRegisteredResourcesRatio: 0.0\n",
      "Warning::Spark Session already created, some configs may not take.\n",
      "07:52:22.490 [Thread-3] INFO  org.apache.spark.sql.internal.SharedState - Setting hive.metastore.warehouse.dir ('null') to the value of spark.sql.warehouse.dir.\n",
      "07:52:22.493 [Thread-3] INFO  org.apache.spark.sql.internal.SharedState - Warehouse path is 'file:/opt/spark/notebook/spark-warehouse'.\n",
      "07:52:22.514 [Thread-3] INFO  org.sparkproject.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@39d743dd{/SQL,null,AVAILABLE,@Spark}\n",
      "07:52:22.516 [Thread-3] INFO  org.sparkproject.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@5391bfef{/SQL/json,null,AVAILABLE,@Spark}\n",
      "07:52:22.518 [Thread-3] INFO  org.sparkproject.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@639c5516{/SQL/execution,null,AVAILABLE,@Spark}\n",
      "07:52:22.519 [Thread-3] INFO  org.sparkproject.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@47f9b6fe{/SQL/execution/json,null,AVAILABLE,@Spark}\n",
      "07:52:22.522 [Thread-3] INFO  org.sparkproject.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@4f48167e{/static/sql,null,AVAILABLE,@Spark}\n",
      "07:52:23.052 [Thread-3] WARN  org.apache.spark.sql.SparkSession - Using an existing Spark session; only runtime SQL configurations will take effect.\n"
     ]
    }
   ],
   "source": [
    "spark = (\n",
    "    SparkSession.builder\n",
    "    .appName(\"Spark NLP\")\n",
    "    .master(\"spark://spark-master:7077\")\n",
    "    .getOrCreate()\n",
    ")\n",
    "\n",
    "spark = sparknlp.start()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f7b5b5df-b10b-4305-971f-2ddc50a4cae5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "recognize_entities_dl download started this may take some time.\n",
      "07:55:14.783 [Thread-3] WARN  com.amazonaws.ShadedByJSLservices.s3.internal.S3AbortableInputStream - Not all bytes were read from the S3ObjectInputStream, aborting HTTP connection. This is likely an error and may result in sub-optimal behavior. Request only the bytes you need via a ranged GET or drain the input stream after use.\n",
      "Approx size to download 159 MB\n",
      "[ | ]07:55:15.636 [dispatcher-BlockManagerMaster] INFO  org.apache.spark.storage.BlockManagerInfo - Removed broadcast_35_piece0 on spark-master:7082 in memory (size: 44.6 KiB, free: 419.6 MiB)\n",
      "07:55:15.640 [dispatcher-BlockManagerMaster] INFO  org.apache.spark.storage.BlockManagerInfo - Removed broadcast_36_piece0 on spark-master:7082 in memory (size: 3.0 KiB, free: 419.6 MiB)\n",
      "[OK!]\n"
     ]
    }
   ],
   "source": [
    "pipeline = PretrainedPipeline('recognize_entities_dl', 'en')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ea939e23-4665-4dc7-a140-a1dfd0295231",
   "metadata": {},
   "outputs": [],
   "source": [
    "result = pipeline.annotate('The Mona Lisa is a 16th century oil painting created by Leonardo')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "827cefd4-f76e-48ef-bfbc-5552386e08b4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'entities': ['Mona Lisa', 'Leonardo'],\n",
       " 'document': ['The Mona Lisa is a 16th century oil painting created by Leonardo'],\n",
       " 'token': ['The',\n",
       "  'Mona',\n",
       "  'Lisa',\n",
       "  'is',\n",
       "  'a',\n",
       "  '16th',\n",
       "  'century',\n",
       "  'oil',\n",
       "  'painting',\n",
       "  'created',\n",
       "  'by',\n",
       "  'Leonardo'],\n",
       " 'ner': ['O',\n",
       "  'B-PER',\n",
       "  'I-PER',\n",
       "  'O',\n",
       "  'O',\n",
       "  'O',\n",
       "  'O',\n",
       "  'O',\n",
       "  'O',\n",
       "  'O',\n",
       "  'O',\n",
       "  'B-PER'],\n",
       " 'embeddings': ['The',\n",
       "  'Mona',\n",
       "  'Lisa',\n",
       "  'is',\n",
       "  'a',\n",
       "  '16th',\n",
       "  'century',\n",
       "  'oil',\n",
       "  'painting',\n",
       "  'created',\n",
       "  'by',\n",
       "  'Leonardo'],\n",
       " 'sentence': ['The Mona Lisa is a 16th century oil painting created by Leonardo']}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
